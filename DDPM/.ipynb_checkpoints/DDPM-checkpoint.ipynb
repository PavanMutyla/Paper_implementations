{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f7ec925-815f-4e18-9529-78425fff84c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17169b6d-7054-4e20-8c73-fe3ea04adf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "class LinearScehduler:\n",
    "    def __init__(self, num_timestamps, beta_start, beta_end):\n",
    "        self.num_timestamps = num_timestamps\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "\n",
    "        self.betas = torch.linspace(beta_start, beta_end, num_timestamps) # To linearly increase BETA from start to end, we will have BETA from 0 to T\n",
    "        self.alphas = 1. - self.betas \n",
    "        self.alpha_cumilative_product = torch.cumprod(self.alphas, dim = 0)\n",
    "        self.alpha_sqroot_cumilative_prod = torch.sqrt(self.alpha_cumilative_product)\n",
    "        self.one_minus_alpha_squareroot = torch.sqrt( 1. - self.alpha_cumilative_product)\n",
    "\n",
    "\n",
    "    def add_noise(self, original_image, noise,t ):\n",
    "        \"\"\"\n",
    "        add noise to the image in the forward process\n",
    "        the images and noise will be of shape BxCxHxW and a 1D tensor for time stamp 't' of size 'B'\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        Forward method for diffusion\n",
    "        :param original: Image on which noise is to be applied\n",
    "        :param noise: Random Noise Tensor (from normal dist)\n",
    "        :param t: timestep of the forward process of shape -> (B,)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        shape = original_image.shape \n",
    "        batch_size = shape[0]\n",
    "\n",
    "        alpha_sqrt_cum_prod = self.alpha_sqroot_cumilative_prod[t].reshape(batch_size)\n",
    "        one_minus_alphs_sqrt = self.one_minus_alpha_squareroot[t].reshape(batch_size)\n",
    "\n",
    "        for _ in range(len(shape)-1):\n",
    "            \"\"\"Reshape aplha sqrt and alpha-1 sqrt to Bx1x1x1\"\"\"\n",
    "            alpha_sqrt_cum_prod = alpha_sqrt_cum_prod.unsqueeze(-1)\n",
    "            one_minus_alphs_sqrt = one_minus_alphs_sqrt.unsqueeze(-1)\n",
    "        return alpha_sqrt_cum_prod*original_image + one_minus_alphs_sqrt*noise\n",
    "\n",
    "    def reverse_process(self, xt, noise_predicted, t):\n",
    "        \"\"\"\n",
    "        Forward method for diffusion\n",
    "        :param original: Image on which noise is to be applied\n",
    "        :param noise: Random Noise Tensor (from normal dist)\n",
    "        :param t: timestep of the forward process of shape -> (B,)\n",
    "        :return: tuple of (mean, image), it returns the predicted mean of the distribution and the predicted denoised image\n",
    "        \"\"\"\n",
    "        x0 = (xt - (self.one_minus_alpha_squareroot[t]*noise_predicted)) / self.alpha_sqroot_cumilative_prod[t]\n",
    "\n",
    "        x0 = torch.clamp(x0, -1., 1.)\n",
    "\n",
    "        mean = xt - ((self.betas[t]*noise_predicted) / self.alpha_sqroot_cumilative_prod[t])\n",
    "        mean = mean / torch.sqrt(self.alphas[t])\n",
    "\n",
    "        if t==0:\n",
    "            return mean, x0\n",
    "        else:\n",
    "            variance = (1. - self.alphas[t]) * (1.- self.alpha_cumilative_product[t])\n",
    "            variance = variance / (1. - self.alphas[t])\n",
    "            sigma = variance ** 0.5 \n",
    "            z = torch.randn(xt.shape).to(xt.device)\n",
    "            #return the sample from the distribution using Reparameterization trick\n",
    "            return mean + sigma*z, x0\n",
    "\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b76637b-f578-4a5c-9fd0-f5c0ce7ca9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "class TimeEmbed(nn.Module):\n",
    "\n",
    "    \"\"\"Takes time stam't' and the required embeddings dimnestion.\n",
    "    Then 't' is passed to Embedding followed by Linear layer, acitvation function and a final Linear layer:\n",
    "    This is done to project the timestamp values as vectors.\n",
    "    return: BxD embedding representation of B time steps.\n",
    "    \"\"\"    \n",
    "    \n",
    "    def __init__(self, t_embed_dim):\n",
    "        super().__init__()\n",
    "        self.t_embed_dim = t_embed_dim\n",
    "        self.fc = nn.Linear(t_embed_dim, t_embed_dim)\n",
    "        self.swish = Swish()\n",
    "    \n",
    "    def forward(self, t):\n",
    "\n",
    "        # Factor: 10000^(2i/d_model)\n",
    "        factor = 10000 ** (torch.arange(\n",
    "            start=0, end=self.t_embed_dim // 2, dtype=torch.float32, device=t.device\n",
    "        ) / (self.t_embed_dim // 2))\n",
    "\n",
    "        # Compute embeddings\n",
    "        t_emb = t[:, None] / factor  # Shape: (B, t_embed_dim // 2)\n",
    "        t_emb = torch.cat([torch.sin(t_emb), torch.cos(t_emb)], dim=-1)  # Shape: (B, t_embed_dim)\n",
    "\n",
    "        # Pass through fully connected layer and Swish activation\n",
    "        t_emb = self.swish(self.fc(t_emb))  # Final projection with non-linearity\n",
    "        return t_emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75454cfb-5e22-4515-8df1-369eed273af2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (4064722152.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    class D\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "class Down_block(nn.Module):\n",
    "    def __init__(self,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf83a5ca-8fad-40f6-bfda-ed0d507fe9a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
